{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Epoch 1/125\n",
      "781/781 [==============================] - 411s 527ms/step - loss: 1.8718 - accuracy: 0.4336 - val_loss: 1.7342 - val_accuracy: 0.5346\n",
      "Epoch 2/125\n",
      "781/781 [==============================] - 419s 537ms/step - loss: 1.2428 - accuracy: 0.5975 - val_loss: 1.2325 - val_accuracy: 0.6392\n",
      "Epoch 3/125\n",
      "781/781 [==============================] - 422s 541ms/step - loss: 1.0692 - accuracy: 0.6570 - val_loss: 1.0544 - val_accuracy: 0.6865\n",
      "Epoch 4/125\n",
      "781/781 [==============================] - 379s 486ms/step - loss: 0.9696 - accuracy: 0.6937 - val_loss: 0.9190 - val_accuracy: 0.7216\n",
      "Epoch 5/125\n",
      "781/781 [==============================] - 381s 488ms/step - loss: 0.9023 - accuracy: 0.7177 - val_loss: 0.8917 - val_accuracy: 0.7341\n",
      "Epoch 6/125\n",
      "781/781 [==============================] - 394s 505ms/step - loss: 0.8578 - accuracy: 0.7365 - val_loss: 0.7587 - val_accuracy: 0.7760\n",
      "Epoch 7/125\n",
      "781/781 [==============================] - 391s 501ms/step - loss: 0.8196 - accuracy: 0.7507 - val_loss: 0.8351 - val_accuracy: 0.7591\n",
      "Epoch 8/125\n",
      "781/781 [==============================] - 378s 485ms/step - loss: 0.7952 - accuracy: 0.7589 - val_loss: 0.7520 - val_accuracy: 0.7831\n",
      "Epoch 9/125\n",
      "781/781 [==============================] - 372s 477ms/step - loss: 0.7645 - accuracy: 0.7738 - val_loss: 0.7290 - val_accuracy: 0.7928\n",
      "Epoch 10/125\n",
      "781/781 [==============================] - 369s 472ms/step - loss: 0.7491 - accuracy: 0.7807 - val_loss: 0.8043 - val_accuracy: 0.7742\n",
      "Epoch 11/125\n",
      "781/781 [==============================] - 368s 471ms/step - loss: 0.7382 - accuracy: 0.7855 - val_loss: 0.7026 - val_accuracy: 0.8019\n",
      "Epoch 12/125\n",
      "781/781 [==============================] - 372s 477ms/step - loss: 0.7212 - accuracy: 0.7931 - val_loss: 0.6805 - val_accuracy: 0.8088\n",
      "Epoch 13/125\n",
      "781/781 [==============================] - 369s 473ms/step - loss: 0.7124 - accuracy: 0.7971 - val_loss: 0.6851 - val_accuracy: 0.8081\n",
      "Epoch 14/125\n",
      "781/781 [==============================] - 369s 472ms/step - loss: 0.7049 - accuracy: 0.7982 - val_loss: 0.8036 - val_accuracy: 0.7827\n",
      "Epoch 15/125\n",
      "781/781 [==============================] - 369s 473ms/step - loss: 0.6925 - accuracy: 0.8058 - val_loss: 0.6795 - val_accuracy: 0.8160\n",
      "Epoch 16/125\n",
      "781/781 [==============================] - 373s 478ms/step - loss: 0.6816 - accuracy: 0.8088 - val_loss: 0.6927 - val_accuracy: 0.8125\n",
      "Epoch 17/125\n",
      "781/781 [==============================] - 371s 474ms/step - loss: 0.6836 - accuracy: 0.8077 - val_loss: 0.6443 - val_accuracy: 0.8298\n",
      "Epoch 18/125\n",
      "781/781 [==============================] - 369s 472ms/step - loss: 0.6689 - accuracy: 0.8160 - val_loss: 0.6916 - val_accuracy: 0.8167\n",
      "Epoch 19/125\n",
      "781/781 [==============================] - 369s 472ms/step - loss: 0.6670 - accuracy: 0.8149 - val_loss: 0.6706 - val_accuracy: 0.8192\n",
      "Epoch 20/125\n",
      "781/781 [==============================] - 371s 475ms/step - loss: 0.6573 - accuracy: 0.8205 - val_loss: 0.7080 - val_accuracy: 0.8098\n",
      "Epoch 21/125\n",
      "781/781 [==============================] - 369s 473ms/step - loss: 0.6615 - accuracy: 0.8201 - val_loss: 0.6811 - val_accuracy: 0.8247\n",
      "Epoch 22/125\n",
      "781/781 [==============================] - 368s 471ms/step - loss: 0.6515 - accuracy: 0.8239 - val_loss: 0.6485 - val_accuracy: 0.8317\n",
      "Epoch 23/125\n",
      "781/781 [==============================] - 370s 474ms/step - loss: 0.6464 - accuracy: 0.8241 - val_loss: 0.7265 - val_accuracy: 0.8058\n",
      "Epoch 24/125\n",
      "781/781 [==============================] - 373s 477ms/step - loss: 0.6436 - accuracy: 0.8273 - val_loss: 0.6459 - val_accuracy: 0.8318\n",
      "Epoch 25/125\n",
      "781/781 [==============================] - 375s 480ms/step - loss: 0.6420 - accuracy: 0.8282 - val_loss: 0.6026 - val_accuracy: 0.8470\n",
      "Epoch 26/125\n",
      "781/781 [==============================] - 372s 476ms/step - loss: 0.6373 - accuracy: 0.8298 - val_loss: 0.6232 - val_accuracy: 0.8387\n",
      "Epoch 27/125\n",
      "781/781 [==============================] - 364s 467ms/step - loss: 0.6379 - accuracy: 0.8286 - val_loss: 0.6741 - val_accuracy: 0.8265\n",
      "Epoch 28/125\n",
      "781/781 [==============================] - 364s 466ms/step - loss: 0.6358 - accuracy: 0.8303 - val_loss: 0.6147 - val_accuracy: 0.8427\n",
      "Epoch 29/125\n",
      "781/781 [==============================] - 371s 475ms/step - loss: 0.6281 - accuracy: 0.8331 - val_loss: 0.5965 - val_accuracy: 0.8477\n",
      "Epoch 30/125\n",
      "781/781 [==============================] - 377s 482ms/step - loss: 0.6292 - accuracy: 0.8316 - val_loss: 0.6587 - val_accuracy: 0.8283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/125\n",
      "781/781 [==============================] - 377s 483ms/step - loss: 0.6269 - accuracy: 0.8351 - val_loss: 0.5909 - val_accuracy: 0.8551\n",
      "Epoch 32/125\n",
      "781/781 [==============================] - 374s 478ms/step - loss: 0.6268 - accuracy: 0.8339 - val_loss: 0.5844 - val_accuracy: 0.8487\n",
      "Epoch 33/125\n",
      "781/781 [==============================] - 372s 476ms/step - loss: 0.6177 - accuracy: 0.8377 - val_loss: 0.6470 - val_accuracy: 0.8372\n",
      "Epoch 34/125\n",
      "781/781 [==============================] - 372s 476ms/step - loss: 0.6233 - accuracy: 0.8336 - val_loss: 0.6647 - val_accuracy: 0.8312\n",
      "Epoch 35/125\n",
      "781/781 [==============================] - 369s 473ms/step - loss: 0.6135 - accuracy: 0.8384 - val_loss: 0.6638 - val_accuracy: 0.8311\n",
      "Epoch 36/125\n",
      "781/781 [==============================] - 364s 466ms/step - loss: 0.6137 - accuracy: 0.8381 - val_loss: 0.6829 - val_accuracy: 0.8231\n",
      "Epoch 37/125\n",
      "781/781 [==============================] - 362s 464ms/step - loss: 0.6179 - accuracy: 0.8374 - val_loss: 0.6187 - val_accuracy: 0.8456\n",
      "Epoch 38/125\n",
      "781/781 [==============================] - 362s 463ms/step - loss: 0.6089 - accuracy: 0.8406 - val_loss: 0.6348 - val_accuracy: 0.8344\n",
      "Epoch 39/125\n",
      "781/781 [==============================] - 359s 460ms/step - loss: 0.6137 - accuracy: 0.8402 - val_loss: 0.6047 - val_accuracy: 0.8544\n",
      "Epoch 40/125\n",
      "781/781 [==============================] - 360s 460ms/step - loss: 0.6051 - accuracy: 0.8431 - val_loss: 0.6480 - val_accuracy: 0.8349\n",
      "Epoch 41/125\n",
      "781/781 [==============================] - 360s 461ms/step - loss: 0.6069 - accuracy: 0.8410 - val_loss: 0.5955 - val_accuracy: 0.8505\n",
      "Epoch 42/125\n",
      "781/781 [==============================] - 362s 464ms/step - loss: 0.6054 - accuracy: 0.8433 - val_loss: 0.6171 - val_accuracy: 0.8450\n",
      "Epoch 43/125\n",
      "781/781 [==============================] - 360s 461ms/step - loss: 0.6075 - accuracy: 0.8426 - val_loss: 0.6240 - val_accuracy: 0.8412\n",
      "Epoch 44/125\n",
      "781/781 [==============================] - 361s 462ms/step - loss: 0.5993 - accuracy: 0.8449 - val_loss: 0.5990 - val_accuracy: 0.8490\n",
      "Epoch 45/125\n",
      "781/781 [==============================] - 362s 464ms/step - loss: 0.6001 - accuracy: 0.8447 - val_loss: 0.5855 - val_accuracy: 0.8576\n",
      "Epoch 46/125\n",
      "781/781 [==============================] - 14772s 19s/step - loss: 0.5998 - accuracy: 0.8448 - val_loss: 0.5824 - val_accuracy: 0.8549\n",
      "Epoch 47/125\n",
      "781/781 [==============================] - 2590s 3s/step - loss: 0.5976 - accuracy: 0.8462 - val_loss: 0.6182 - val_accuracy: 0.8478\n",
      "Epoch 48/125\n",
      "781/781 [==============================] - 360s 461ms/step - loss: 0.5914 - accuracy: 0.8469 - val_loss: 0.6469 - val_accuracy: 0.8403\n",
      "Epoch 49/125\n",
      "781/781 [==============================] - 361s 462ms/step - loss: 0.5957 - accuracy: 0.8477 - val_loss: 0.6082 - val_accuracy: 0.8477\n",
      "Epoch 50/125\n",
      "781/781 [==============================] - 361s 462ms/step - loss: 0.5916 - accuracy: 0.8497 - val_loss: 0.6634 - val_accuracy: 0.8361\n",
      "Epoch 51/125\n",
      "781/781 [==============================] - 361s 462ms/step - loss: 0.5940 - accuracy: 0.8480 - val_loss: 0.5926 - val_accuracy: 0.8511\n",
      "Epoch 52/125\n",
      "781/781 [==============================] - 363s 465ms/step - loss: 0.5941 - accuracy: 0.8475 - val_loss: 0.5616 - val_accuracy: 0.8659\n",
      "Epoch 53/125\n",
      "781/781 [==============================] - 362s 464ms/step - loss: 0.5916 - accuracy: 0.8476 - val_loss: 0.6763 - val_accuracy: 0.8329\n",
      "Epoch 54/125\n",
      "781/781 [==============================] - 364s 466ms/step - loss: 0.5927 - accuracy: 0.8480 - val_loss: 0.5838 - val_accuracy: 0.8560\n",
      "Epoch 55/125\n",
      "781/781 [==============================] - 366s 468ms/step - loss: 0.5899 - accuracy: 0.8490 - val_loss: 0.5682 - val_accuracy: 0.8621\n",
      "Epoch 56/125\n",
      "781/781 [==============================] - 370s 474ms/step - loss: 0.5869 - accuracy: 0.8507 - val_loss: 0.5557 - val_accuracy: 0.8639\n",
      "Epoch 57/125\n",
      "781/781 [==============================] - 366s 469ms/step - loss: 0.5897 - accuracy: 0.8485 - val_loss: 0.8234 - val_accuracy: 0.8038\n",
      "Epoch 58/125\n",
      "781/781 [==============================] - 367s 470ms/step - loss: 0.5821 - accuracy: 0.8520 - val_loss: 0.5696 - val_accuracy: 0.8598\n",
      "Epoch 59/125\n",
      "781/781 [==============================] - 365s 467ms/step - loss: 0.5864 - accuracy: 0.8496 - val_loss: 0.5787 - val_accuracy: 0.8597\n",
      "Epoch 60/125\n",
      "781/781 [==============================] - 366s 468ms/step - loss: 0.5897 - accuracy: 0.8502 - val_loss: 0.6111 - val_accuracy: 0.8497\n",
      "Epoch 61/125\n",
      "781/781 [==============================] - 362s 463ms/step - loss: 0.5855 - accuracy: 0.8516 - val_loss: 0.5681 - val_accuracy: 0.8615\n",
      "Epoch 62/125\n",
      "781/781 [==============================] - 368s 471ms/step - loss: 0.5866 - accuracy: 0.8504 - val_loss: 0.5864 - val_accuracy: 0.8589\n",
      "Epoch 63/125\n",
      "781/781 [==============================] - 366s 469ms/step - loss: 0.5836 - accuracy: 0.8513 - val_loss: 0.5580 - val_accuracy: 0.8687\n",
      "Epoch 64/125\n",
      "781/781 [==============================] - 360s 461ms/step - loss: 0.5820 - accuracy: 0.8510 - val_loss: 0.6034 - val_accuracy: 0.8519\n",
      "Epoch 65/125\n",
      "781/781 [==============================] - 364s 466ms/step - loss: 0.5852 - accuracy: 0.8518 - val_loss: 0.6188 - val_accuracy: 0.8459\n",
      "Epoch 66/125\n",
      "781/781 [==============================] - 362s 463ms/step - loss: 0.5830 - accuracy: 0.8523 - val_loss: 0.6439 - val_accuracy: 0.8396\n",
      "Epoch 67/125\n",
      "781/781 [==============================] - 363s 465ms/step - loss: 0.5831 - accuracy: 0.8522 - val_loss: 0.6071 - val_accuracy: 0.8503\n",
      "Epoch 68/125\n",
      "781/781 [==============================] - 364s 466ms/step - loss: 0.5828 - accuracy: 0.8523 - val_loss: 0.5708 - val_accuracy: 0.8632\n",
      "Epoch 69/125\n",
      "781/781 [==============================] - 363s 465ms/step - loss: 0.5792 - accuracy: 0.8537 - val_loss: 0.5703 - val_accuracy: 0.8623\n",
      "Epoch 70/125\n",
      "781/781 [==============================] - 363s 465ms/step - loss: 0.5811 - accuracy: 0.8531 - val_loss: 0.5912 - val_accuracy: 0.8567\n",
      "Epoch 71/125\n",
      "781/781 [==============================] - 363s 464ms/step - loss: 0.5838 - accuracy: 0.8545 - val_loss: 0.5640 - val_accuracy: 0.8646\n",
      "Epoch 72/125\n",
      "781/781 [==============================] - 368s 471ms/step - loss: 0.5817 - accuracy: 0.8523 - val_loss: 0.6281 - val_accuracy: 0.8455\n",
      "Epoch 73/125\n",
      "781/781 [==============================] - 365s 468ms/step - loss: 0.5776 - accuracy: 0.8539 - val_loss: 0.5505 - val_accuracy: 0.8646\n",
      "Epoch 74/125\n",
      "781/781 [==============================] - 362s 463ms/step - loss: 0.5746 - accuracy: 0.8550 - val_loss: 0.6416 - val_accuracy: 0.8435\n",
      "Epoch 75/125\n",
      "781/781 [==============================] - 361s 462ms/step - loss: 0.5771 - accuracy: 0.8546 - val_loss: 0.6244 - val_accuracy: 0.8459\n",
      "Epoch 76/125\n",
      "781/781 [==============================] - 364s 466ms/step - loss: 0.5748 - accuracy: 0.8548 - val_loss: 0.5940 - val_accuracy: 0.8554\n",
      "Epoch 77/125\n",
      "781/781 [==============================] - 362s 464ms/step - loss: 0.5281 - accuracy: 0.8694 - val_loss: 0.5325 - val_accuracy: 0.8803\n",
      "Epoch 78/125\n",
      "781/781 [==============================] - 362s 464ms/step - loss: 0.5126 - accuracy: 0.8731 - val_loss: 0.5567 - val_accuracy: 0.8654\n",
      "Epoch 79/125\n",
      "781/781 [==============================] - 362s 464ms/step - loss: 0.5051 - accuracy: 0.8760 - val_loss: 0.5459 - val_accuracy: 0.8709\n",
      "Epoch 80/125\n",
      "781/781 [==============================] - 366s 469ms/step - loss: 0.5070 - accuracy: 0.8741 - val_loss: 0.5322 - val_accuracy: 0.8768\n",
      "Epoch 81/125\n",
      "781/781 [==============================] - 364s 465ms/step - loss: 0.4969 - accuracy: 0.8768 - val_loss: 0.5019 - val_accuracy: 0.8818\n",
      "Epoch 82/125\n",
      "781/781 [==============================] - 364s 467ms/step - loss: 0.4942 - accuracy: 0.8762 - val_loss: 0.4986 - val_accuracy: 0.8822\n",
      "Epoch 83/125\n",
      "781/781 [==============================] - 364s 466ms/step - loss: 0.4870 - accuracy: 0.8790 - val_loss: 0.5054 - val_accuracy: 0.8801\n",
      "Epoch 84/125\n",
      "781/781 [==============================] - 361s 462ms/step - loss: 0.4833 - accuracy: 0.8776 - val_loss: 0.4917 - val_accuracy: 0.8820\n",
      "Epoch 85/125\n",
      "781/781 [==============================] - 363s 464ms/step - loss: 0.4793 - accuracy: 0.8799 - val_loss: 0.4787 - val_accuracy: 0.8838\n",
      "Epoch 86/125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 363s 465ms/step - loss: 0.4739 - accuracy: 0.8811 - val_loss: 0.4999 - val_accuracy: 0.8790\n",
      "Epoch 87/125\n",
      "781/781 [==============================] - 405s 519ms/step - loss: 0.4757 - accuracy: 0.8795 - val_loss: 0.5233 - val_accuracy: 0.8725\n",
      "Epoch 88/125\n",
      "781/781 [==============================] - 712s 912ms/step - loss: 0.4760 - accuracy: 0.8785 - val_loss: 0.5213 - val_accuracy: 0.8747\n",
      "Epoch 89/125\n",
      "781/781 [==============================] - 30392s 39s/step - loss: 0.4784 - accuracy: 0.8787 - val_loss: 0.4761 - val_accuracy: 0.8868\n",
      "Epoch 90/125\n",
      "781/781 [==============================] - 414s 530ms/step - loss: 0.4661 - accuracy: 0.8821 - val_loss: 0.5351 - val_accuracy: 0.8683\n",
      "Epoch 91/125\n",
      "781/781 [==============================] - 387s 495ms/step - loss: 0.4743 - accuracy: 0.8791 - val_loss: 0.5272 - val_accuracy: 0.8714\n",
      "Epoch 92/125\n",
      "781/781 [==============================] - 353s 452ms/step - loss: 0.4660 - accuracy: 0.8809 - val_loss: 0.5038 - val_accuracy: 0.8791\n",
      "Epoch 93/125\n",
      "781/781 [==============================] - 371s 475ms/step - loss: 0.4706 - accuracy: 0.8780 - val_loss: 0.4769 - val_accuracy: 0.8845\n",
      "Epoch 94/125\n",
      "781/781 [==============================] - 388s 497ms/step - loss: 0.4646 - accuracy: 0.8793 - val_loss: 0.5295 - val_accuracy: 0.8700\n",
      "Epoch 95/125\n",
      "781/781 [==============================] - 461s 591ms/step - loss: 0.4644 - accuracy: 0.8808 - val_loss: 0.4979 - val_accuracy: 0.8788\n",
      "Epoch 96/125\n",
      "781/781 [==============================] - 474s 607ms/step - loss: 0.4652 - accuracy: 0.8801 - val_loss: 0.5050 - val_accuracy: 0.8735\n",
      "Epoch 97/125\n",
      "781/781 [==============================] - 402s 515ms/step - loss: 0.4566 - accuracy: 0.8821 - val_loss: 0.4806 - val_accuracy: 0.8826\n",
      "Epoch 98/125\n",
      "781/781 [==============================] - 401s 514ms/step - loss: 0.4646 - accuracy: 0.8803 - val_loss: 0.5054 - val_accuracy: 0.8713\n",
      "Epoch 99/125\n",
      "781/781 [==============================] - 447s 572ms/step - loss: 0.4575 - accuracy: 0.8818 - val_loss: 0.5041 - val_accuracy: 0.8714\n",
      "Epoch 100/125\n",
      "781/781 [==============================] - 433s 555ms/step - loss: 0.4606 - accuracy: 0.8823 - val_loss: 0.5042 - val_accuracy: 0.8766\n",
      "Epoch 101/125\n",
      "613/781 [======================>.......] - ETA: 1:27 - loss: 0.4522 - accuracy: 0.8831"
     ]
    }
   ],
   "source": [
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    if epoch > 100:\n",
    "        lrate = 0.0003\n",
    "    return lrate\n",
    " \n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    " \n",
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n",
    " \n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)\n",
    " \n",
    "weight_decay = 1e-4\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    " \n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    " \n",
    "model.summary()\n",
    " \n",
    "#data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)\n",
    " \n",
    "#training\n",
    "batch_size = 64\n",
    " \n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=125,\\\n",
    "                    verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)])\n",
    "#save to disk\n",
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights('model.h5') \n",
    " \n",
    "#testing\n",
    "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
    "#print((scores[1]*100,scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "cnn.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
